---
layout: post
title: go-gecache（一）-LRU缓存淘汰策略
date: 2020-07-24
categories: 分布式缓存
tags: [go,分布式缓存]
description: 文章金句。
---
<h1>LRU缓存淘汰策略</h1>
常用的三种缓存淘汰算法:FIFO、LFU、LRU

<h2>FIFO/LFU/LRU 算法简介</h2>
GeeCache 的缓存全部存储在内存中，内存是有限的，因此不可能无限制地添加数据。假定我们设置缓存能够使用的内存大小为 N，那么在某一个时间点，添加了某一条缓存记录之后，占用内存超过了 N，这个时候就需要从缓存中移除一条或多条数据了。那移除谁呢？我们肯定希望尽可能移除“没用”的数据，那如何判定数据“有用”还是“没用”呢？
  <h3>FIFO(First In First Out)</h3>
  淘汰理论:采用先进先出的理论，认为最早添加的记录，其不再被使用的可能性比刚添加的可能性大。<br>
  实现:创建一个队列，新增记录添加到队尾，每次内存不够时，淘汰队首。<br>
  缺点:但是很多场景中，部分记录虽然是最早添加进去的却是经常被访问的，而不得不因为呆的时间过长而被淘汰，这类数据被频繁的添加进缓存，又被淘汰出去，导致缓存命中率降低。<br>
  <h3>LFU (lEAST Frequently Used)</h3>
  淘汰理论:最少使用，淘汰缓存中访问频率最低的记录。LFU认为，如果数据过去被访问多次，那么将来被访问的频率也更高。<br>
  实现:LFU的实现需要维护一个按照访问次数排序的队列，每次访问，访问次数+1，队列重新排序，淘汰时选择访问率最少的即可。<br>
  优点:LFU算法的命中率比较高<br>
  缺点:1、维护每个记录的访问次数，对内存的消耗是很高的。2、如果数据的访问模式发生变化，LFU需要较长的时间去适应，也就是说LFU算法受历史数据的影响比较大。<br>
  <h3>LRU(Least Recently Used)</h3>
  淘汰理论:最近最少使用，相对于仅考虑时间因素的 FIFO 和仅考虑访问频率的 LFU，LRU 算法可以认为是相对平衡的一种淘汰算法。
  实现:维护一个队列，如果某条记录被访问了，则移动到队尾，那么队首则是最近最少访问的数据，淘汰该条数据即可。
  
<h2>LRU 的算法实现</h2>  
 ###2.1核心数据结构
    ![img](https://geektutu.com/post/geecache-day1/lru.jpg)

 核心数据结构:<br>
  1、绿色的是字典(map)，存储键和值的映射关系。这样根据某个键(key)查找对应的值(value)的复杂是O(1)，在字典中插入一条记录的复杂度也是O(1)。<br>
  2、红色的是双向链表(double linked list)实现的队列。将所有的值放到双向链表中，这样，当访问到某个值时，将其移动到队尾的复杂度是O(1)，在队尾新增一条记录以及删除一条记录的复杂度均为O(1) <br>
  接下来我们创建一个包含字典和双向链表的结构体类型 Cache，方便实现后续的增删查改操作
  
  代码实现:
  [LRU代码实现](https://gitee.com/sixnine/gomoudle_self_help_learning/blob/master/geeCache/cache.go)
  [LRU测试](https://gitee.com/sixnine/gomoudle_self_help_learning/blob/master/geeCache/cache_test.go)

摘自[7天学会geecache](https://geektutu.com/post/geecache.html)
，如有侵犯，请联系本人，此篇文章只作为学习记录





